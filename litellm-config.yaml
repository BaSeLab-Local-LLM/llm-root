# ==============================================================================
#                         LITELLM PROXY CONFIGURATION
# ==============================================================================
# This file configures the LiteLLM proxy to connect to your local vLLM server.
# Modify model_list to add more models or change settings.
# ==============================================================================

# Model Configuration
# LITELLM_MODEL_ID, VLLM_API_BASE, VLLM_MAX_MODEL_LEN은
# docker-compose.yml에서 환경변수로 주입됩니다.
model_list:
  - model_name: "Local LLM"
    litellm_params:
      model: "os.environ/LITELLM_MODEL_ID"
      api_base: "os.environ/VLLM_API_BASE"
      api_key: "not-needed"
      rpm: 100
      tpm: 100000
    model_info:
      description: "Local VLM running on vLLM (vision + text)"
      max_tokens: 4096
      supports_vision: true

# LiteLLM Settings
litellm_settings:
  # Caching (set to true and add Redis for production)
  cache: false
  
  # Retry settings
  num_retries: 3
  request_timeout: 180
  
  # Logging
  set_verbose: false
  json_logs: true
  
  # Drop unsupported params instead of erroring
  drop_params: true

# Router Settings
router_settings:
  routing_strategy: "least-busy"
  num_retries: 2
  timeout: 180

# General Proxy Settings
general_settings:
  # Database connection (from environment)
  database_url: "os.environ/DATABASE_URL"
  master_key: "os.environ/LITELLM_MASTER_KEY"
  
  # Enable Admin UI
  enable_admin_ui: true
  
  # Store model info in DB
  store_model_in_db: true
  
  # CORS: LiteLLM은 Docker 내부 네트워크에서만 접근되므로 별도 설정 불필요
  # (CORS는 FastAPI 백엔드에서 ALLOWED_ORIGINS 환경변수로 제어)
