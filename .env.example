# ==============================================================================
#                    LOCAL LLM DEPLOYMENT CONFIGURATION
# ==============================================================================
# 환경별 설정 파일:
#   .env.local   — 로컬 개발/테스트 (DEBUG=true, localhost)
#   .env.server  — 서버 배포 (DEBUG=false, 실제 도메인)
#
# 사용법:
#   cp .env.example .env.local   # 로컬용 생성
#   cp .env.example .env.server  # 서버용 생성
#   docker compose --env-file .env.local up -d    # 로컬 실행
#   docker compose --env-file .env.server up -d   # 서버 실행
# ==============================================================================


# //////////////////////////////////////////////////////////////////////////////
# //                                                                          //
# //  기본값 (필요 시 커스터마이징 가능)                                      //
# //                                                                          //
# //////////////////////////////////////////////////////////////////////////////

# ================================ GPU SETTINGS ================================

# 사용할 NVIDIA GPU 장치 번호
# "0" = 첫 번째 GPU, "0,1" = 멀티 GPU, "none" = GPU 비활성화
NVIDIA_VISIBLE_DEVICES=0

# GPU 메모리 사용 비율 (0.0 ~ 1.0)
# 높을수록 더 많은 VRAM 사용. OOM 에러 시 낮추세요
VLLM_GPU_MEMORY_UTILIZATION=0.85

# 최대 컨텍스트 길이 (토큰 수)
# 길수록 더 많은 VRAM 필요. 옵션: 2048, 4096, 8192, 16384, 32768
VLLM_MAX_MODEL_LEN=4096

# 모델 가중치 데이터 타입
# "auto" = 자동 감지, "float16", "bfloat16"
VLLM_DTYPE=auto

# ================================ CPU SETTINGS ================================

# vLLM 컨테이너 CPU 코어 수 (모델 추론 처리)
VLLM_CPU_LIMIT=12

# LiteLLM 컨테이너 CPU 코어 수 (API 게이트웨이)
LITELLM_CPU_LIMIT=4

# PostgreSQL 컨테이너 CPU 코어 수
POSTGRES_CPU_LIMIT=2

# Frontend 컨테이너 CPU 코어 수 (Nginx)
FRONTEND_CPU_LIMIT=1

# 병렬 연산 스레드 수 (OpenMP / NumExpr / MKL)
OMP_NUM_THREADS=8
NUMEXPR_MAX_THREADS=8
MKL_NUM_THREADS=8

# ================================ MEMORY SETTINGS =============================

# vLLM 컨테이너 메모리 (모델 + KV 캐시)
VLLM_MEMORY_LIMIT=24g

# LiteLLM 컨테이너 메모리
LITELLM_MEMORY_LIMIT=2g

# PostgreSQL 컨테이너 메모리
POSTGRES_MEMORY_LIMIT=2g

# Frontend 컨테이너 메모리
FRONTEND_MEMORY_LIMIT=512m

# PostgreSQL shared_buffers (보통 POSTGRES_MEMORY_LIMIT의 25%)
POSTGRES_SHARED_BUFFERS=512MB

# ================================ VLLM ADVANCED ===============================

# 최대 동시 시퀀스 수 (높을수록 동시 사용자↑, 메모리↑)
VLLM_MAX_NUM_SEQS=64

# CPU 메모리 오프로딩 (GB). VRAM 부족 시 RAM으로 보조. 0 = 비활성화
VLLM_CPU_OFFLOAD_GB=0

# 텐서 병렬 크기. 단일 GPU: 1, 멀티 GPU: GPU 수
VLLM_TENSOR_PARALLEL_SIZE=1

# KV 캐시 스왑 공간 (GB)
VLLM_SWAP_SPACE=4

# ================================ PERFORMANCE OPTIMIZATION ====================

# Prefix Caching — 공통 시스템 프롬프트의 KV 캐시 재사용
VLLM_ENABLE_PREFIX_CACHING=true

# Chunked Prefill — 긴 프롬프트를 청크 단위로 처리 (TTFT 개선)
VLLM_ENABLE_CHUNKED_PREFILL=true

# 청크당 최대 프리필 토큰 수
# 512 = 빠른 응답, 1024 = 균형, 2048 = 높은 처리량
VLLM_MAX_NUM_BATCHED_TOKENS=1024

# 양자화 방식. "none", "awq", "gptq", "squeezellm", "fp8"
VLLM_QUANTIZATION=none

# 추측 디코딩용 드래프트 모델 (빈 값 = 비활성화)
# 예: Qwen/Qwen2.5-0.5B-Instruct
VLLM_SPECULATIVE_MODEL=

# 추측 디코딩 예측 토큰 수
VLLM_NUM_SPECULATIVE_TOKENS=5

# KV 캐시 데이터 타입. "auto", "fp8", "fp8_e5m2", "fp8_e4m3"
VLLM_KV_CACHE_DTYPE=auto

# 구조화된 출력(JSON) 생성 백엔드. "outlines", "lm-format-enforcer"
VLLM_GUIDED_DECODING_BACKEND=outlines

# ================================ MODEL SETTINGS ==============================

# HuggingFace 모델 ID — 사용할 LLM 모델
# 비전(이미지 이해) 모델: Qwen/Qwen2.5-VL-3B-Instruct (권장)
# 텍스트 전용 모델: Qwen/Qwen2.5-3B-Instruct, Qwen/Qwen2.5-7B-Instruct-AWQ
VLLM_MODEL=Qwen/Qwen2.5-VL-3B-Instruct

# HuggingFace 토큰 — Llama, Gemma 등 게이트 모델 사용 시 필요
# https://huggingface.co/settings/tokens 에서 발급
HF_TOKEN=

# 모델 캐시 디렉토리 (Docker 볼륨에 저장)
HF_HOME=/root/.cache/huggingface

# ================================ NETWORK PORTS ===============================

# vLLM 내부 포트 (외부 노출 안 함)
VLLM_PORT=8000

# LiteLLM API 게이트웨이 포트 (외부 노출 안 함)
LITELLM_PORT=4000

# FastAPI 백엔드 외부 노출 포트
BACKEND_PORT=8080

# 프론트엔드(Nginx) 외부 노출 포트
FRONTEND_PORT=3000

# PostgreSQL 외부 노출 포트 (서버에서는 방화벽으로 차단 권장)
POSTGRES_PORT=5432

# ================================ DATABASE ====================================

# PostgreSQL 사용자명
POSTGRES_USER=llmadmin

# PostgreSQL 데이터베이스명
POSTGRES_DB=litellm

# ================================ RATE LIMITING ===============================

# 학생 API 키 기본 Rate Limit — 분당 요청 수
DEFAULT_RATE_LIMIT_RPM=10

# 학생 API 키 기본 Rate Limit — 분당 토큰 수
DEFAULT_RATE_LIMIT_TPM=100000

# 학생 API 키 기본 최대 예산 (USD)
DEFAULT_STUDENT_MAX_BUDGET=1.0

# 관리자 API 키 Rate Limit — 분당 요청 수
ADMIN_RATE_LIMIT_RPM=1000

# 관리자 API 키 Rate Limit — 분당 토큰 수
ADMIN_RATE_LIMIT_TPM=1000000

# 관리자 API 키 최대 예산 (USD)
ADMIN_MAX_BUDGET=1000.0

# ================================ FILE UPLOAD =================================

# 최대 요청 본문 크기 (MB) — 이미지/문서 첨부 시 충분히 크게 설정
MAX_REQUEST_BODY_SIZE=50

# 단일 파일 최대 크기 (MB)
MAX_UPLOAD_FILE_SIZE=20

# 이미지 리사이즈 최대 해상도 (px) — 큰 이미지를 이 크기 이내로 리사이즈
# VRAM 절약과 처리 속도 향상을 위해 적절히 설정
MAX_IMAGE_DIMENSION=1280

# ================================ LITELLM ADMIN UI ============================

# LiteLLM 관리 웹 UI 사용자명
LITELLM_UI_USERNAME=admin


# //////////////////////////////////////////////////////////////////////////////
# //                                                                          //
# //  ⚠ 아래 항목은 반드시 사용자가 직접 수정해야 합니다                      //
# //                                                                          //
# //////////////////////////////////////////////////////////////////////////////

# ─── 환경 구분 ────────────────────────────────────────────────────────────────
# 로컬: local  /  서버: production
DEPLOY_ENV=local

# ─── 디버그 모드 ──────────────────────────────────────────────────────────────
# true  → API 문서(/docs) 활성화, SQL 쿼리 로그, Secure 쿠키 비활성화
# false → API 문서 비활성화, HSTS 보안 헤더 추가, Secure 쿠키 활성화
DEBUG=false

# ─── 포트 바인딩 주소 ─────────────────────────────────────────────────────────
# 127.0.0.1 → 로컬 전용 / 리버스 프록시 뒤에서 사용 (권장)
# 0.0.0.0   → 모든 네트워크에서 직접 접근 허용
BIND_ADDRESS=127.0.0.1

# ─── 로그 레벨 ────────────────────────────────────────────────────────────────
# 로컬: INFO 또는 DEBUG  /  서버: WARNING 또는 ERROR
LOG_LEVEL=INFO

# ─── CORS 허용 오리진 ─────────────────────────────────────────────────────────
# 프론트엔드가 접근하는 도메인 (쉼표 구분으로 복수 가능)
# 로컬: http://localhost:3000
# 서버: https://your-domain.com
ALLOWED_ORIGINS=http://localhost:3000

# ─── JWT 토큰 만료 시간 ──────────────────────────────────────────────────────
# 사용자 로그인 세션 유지 시간 (단위: 시간)
JWT_EXPIRE_HOURS=24

# ─── PostgreSQL 비밀번호 ─────────────────────────────────────────────────────
# DB 접속 비밀번호. 생성: openssl rand -hex 16
POSTGRES_PASSWORD=CHANGE_ME_GENERATE_WITH_openssl_rand_hex_16

# ─── JWT 서명 키 ──────────────────────────────────────────────────────────────
# 사용자 인증 토큰 암호화에 사용 (최소 32자). 생성: openssl rand -hex 32
JWT_SECRET_KEY=CHANGE_ME_GENERATE_WITH_openssl_rand_hex_32

# ─── LiteLLM 마스터 키 ───────────────────────────────────────────────────────
# API 게이트웨이 관리자 인증 키. 생성: echo "sk-master-$(openssl rand -hex 24)"
LITELLM_MASTER_KEY=CHANGE_ME_GENERATE_WITH_openssl_rand_hex_32

# ─── LiteLLM 솔트 키 ─────────────────────────────────────────────────────────
# 가상 API 키 해싱용 비밀 값. 생성: openssl rand -hex 16
LITELLM_SALT_KEY=CHANGE_ME_GENERATE_WITH_openssl_rand_hex_16

# ─── LiteLLM Admin UI 비밀번호 ───────────────────────────────────────────────
# LiteLLM 관리 웹 UI 로그인 비밀번호. 생성: openssl rand -base64 18
LITELLM_UI_PASSWORD=CHANGE_ME_SET_SECURE_PASSWORD

# ─── Ngrok 외부 접속 (선택) ───────────────────────────────────────────────────
# docker-compose.ngrok.yml 오버라이드 파일과 함께 사용할 때만 필요
# https://dashboard.ngrok.com 에서 토큰 발급
NGROK_AUTHTOKEN=

# 노출할 내부 대상 서비스
# 프론트 전체 노출(권장): frontend:80
# 백엔드 API만 노출: backend:8000
NGROK_TARGET=frontend:80

# ngrok dashboard/web inspect 포트 (로컬호스트 바인딩)
NGROK_INSPECT_PORT=4040

# 추가 인증(권장): user:password 형식
# 빈 값이면 ngrok URL만 아는 누구나 접속 가능
NGROK_BASIC_AUTH=

# 유료 플랜 고정 도메인 사용 시 설정 (없으면 자동 URL 사용)
NGROK_DOMAIN=
